# -*- coding: utf-8 -*-
"""Shopper Spectrum.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/137o9X1wUbiw2oiShPMEm2FFGkqxNRDE7

**Project Name :Shopper Spectrum: Customer Segmentation and Product Recommendations in E-Commerce**

**Project Type : Unsupervised Machine Learning ‚Äì Clustering

Collaborative Filtering ‚Äì Recommendation System
**

**Contribution - Individual(Mukta Londhe)**

**Project Summary - The project "Shopper Spectrum" focuses on customer segmentation and product recommendations in e-commerce using RFM (Recency, Frequency, Monetary) analysis and collaborative filtering. Key steps include data preprocessing, exploratory data analysis (EDA), and feature engineering to derive RFM metrics. Clustering techniques like KMeans are applied to segment customers into groups such as High-Value, Regular, and Occasional. A product recommendation system uses item-based collaborative filtering to suggest similar products. The solution is deployed via a Streamlit app, allowing users to input RFM values for segmentation or a product name for recommendations. The project enhances customer insights and personalized marketing strategies.**

**GitHub Link -**

**Problem Statement : The global e-commerce industry generates vast amounts of transaction data daily, offering valuable insights into customer purchasing behaviors. Analyzing this data is essential for identifying meaningful customer segments and recommending relevant products to enhance customer experience and drive business growth. This project aims to examine transaction data from an online retail business to uncover patterns in customer purchase behavior, segment customers based on Recency, Frequency, and Monetary (RFM) analysis, and develop a product recommendation system using collaborative filtering techniques.**

**Lets Begin!**

**Know The Data**

**Import Libraries**
"""

## 1. Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from scipy.spatial.distance import cosine
from sklearn.metrics.pairwise import cosine_similarity
import pickle

"""**Load Dataset**"""

## 2. Load Dataset
df = pd.read_csv("online_retail.csv", encoding="ISO-8859-1")
df.head()

"""**Data Cleaning**"""

## 3. Data Cleaning
df.dropna(subset=["CustomerID"], inplace=True)
df = df[~df["InvoiceNo"].str.startswith("C", na=False)]
df = df[(df["Quantity"] > 0) & (df["UnitPrice"] > 0)]
df["TotalPrice"] = df["Quantity"] * df["UnitPrice"]
df["InvoiceDate"] = pd.to_datetime(df["InvoiceDate"])

"""**RFM Analysis**"""

## 4. Feature Engineering: RFM Analysis
snapshot_date = df["InvoiceDate"].max() + pd.Timedelta(days=1)
rfm = df.groupby("CustomerID").agg({
    "InvoiceDate": lambda x: (snapshot_date - x.max()).days,
    "InvoiceNo": "count",
    "TotalPrice": "sum"
})
rfm.rename(columns={"InvoiceDate": "Recency", "InvoiceNo": "Frequency", "TotalPrice": "Monetary"}, inplace=True)

"""****

**Apply KMeans Clustering**
"""

## 5. Normalize RFM and Apply KMeans Clustering
scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm)

"""**Elbow Method**"""

# Find optimal clusters (Elbow Method)
sse = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(rfm_scaled)
    sse.append(kmeans.inertia_)

plt.plot(range(1, 11), sse)
plt.xlabel("Number of Clusters")
plt.ylabel("SSE")
plt.title("Elbow Method")
plt.show()

# Apply KMeans with k=4 (based on elbow)
kmeans = KMeans(n_clusters=4, random_state=42)
rfm["Cluster"] = kmeans.fit_predict(rfm_scaled)

## 6. Label Clusters
def label_cluster(row):
    if row["Recency"] < rfm["Recency"].quantile(0.25) and row["Frequency"] > rfm["Frequency"].quantile(0.75) and row["Monetary"] > rfm["Monetary"].quantile(0.75):
        return "High-Value"
    elif row["Frequency"] > rfm["Frequency"].median() and row["Monetary"] > rfm["Monetary"].median():
        return "Regular"
    elif row["Recency"] > rfm["Recency"].quantile(0.75):
        return "At-Risk"
    else:
        return "Occasional"

rfm["Segment"] = rfm.apply(label_cluster, axis=1)

## 7. Collaborative Filtering
pivot_table = df.pivot_table(index="CustomerID", columns="StockCode", values="Quantity", fill_value=0)
item_similarity = cosine_similarity(pivot_table.T)
item_similarity_df = pd.DataFrame(item_similarity, index=pivot_table.columns, columns=pivot_table.columns)

def recommend_products(product_id, top_n=5):
    similar_scores = item_similarity_df[product_id].sort_values(ascending=False)
    return similar_scores.iloc[1:top_n+1]

# Save models for Streamlit app
pickle.dump(kmeans, open("kmeans_model.pkl", "wb"))
pickle.dump(scaler, open("scaler.pkl", "wb"))
rfm.to_csv("rfm_with_labels.csv")
item_similarity_df.to_pickle("item_similarity.pkl")

print("‚úÖ All models saved. Ready for Streamlit integration.")

"""**Downloading files in local folder **"""

from google.colab import files
files.download('kmeans_model.pkl')
files.download('scaler.pkl')
files.download('item_similarity.pkl')

"""**app.py is downloaded in the same local folder as the above file  and run it locally**"""

##app.py
import streamlit as st
import pandas as pd
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# --- Page Configuration ---
# THIS MUST BE THE FIRST STREAMLIT COMMAND IN YOUR SCRIPT
st.set_page_config(
    page_title="Shopper Spectrum Dashboard",
    page_icon="üõçÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Load Models and Data ---
# Ensure these files are in the same directory as your app.py when you run it
try:
    kmeans = pickle.load(open("kmeans_model.pkl", "rb"))
    scaler = pickle.load(open("scaler.pkl", "rb"))
    item_similarity_df = pd.read_pickle("item_similarity.pkl")

    # You might also want to load the original product data to get actual product names
    # For this example, we'll assume item_similarity_df's index (StockCode) serves as the "Product Name"
    # If you have an 'online_retail.csv' and want to map StockCode to Description:
    # df_original = pd.read_csv("online_retail.csv", encoding="ISO-8859-1")
    # product_code_to_name = df_original[['StockCode', 'Description']].drop_duplicates().set_index('StockCode')['Description'].to_dict()
    # If you implement this, make sure 'online_retail.csv' is also in the same directory.

    st.success("")
except FileNotFoundError:
    st.error("Error: One or more model/data files not found. Make sure 'kmeans_model.pkl', 'scaler.pkl', and 'item_similarity.pkl' are in the same directory as this script.")
    st.stop() # Stop the app if essential files are missing
except Exception as e:
    st.error(f"An error occurred while loading models/data: {e}")
    st.stop()

# --- Sidebar Navigation ---
st.sidebar.title("Navigation")
# The index parameter sets the default selected page. 0 for "Home".
page = st.sidebar.radio("Go to", ["Home", "Clustering", "Recommendation"], index=0)

# --- Home Page ---
if page == "Home":
    st.title("üõçÔ∏è Welcome to Shopper Spectrum Dashboard")
    st.markdown("""
    This interactive dashboard provides insights into your customer base and helps with product recommendations.
    Use the sidebar to navigate between:
    - **Clustering**: Understand different customer segments based on their purchasing behavior.
    - **Recommendation**: Get product suggestions based on item similarity.
    """)


# --- Customer Segmentation (Clustering) Page ---
elif page == "Clustering":
    st.title("üë• Customer Segmentation")
    st.markdown("Enter customer RFM (Recency, Frequency, Monetary) values to predict their segment.")

    # Values from the screenshot
    recency = st.number_input("Recency (days since last purchase):", min_value=0, value=325)
    frequency = st.number_input("Frequency (number of purchases):", min_value=0, value=1)
    monetary = st.number_input("Monetary (total spend):", min_value=0.0, value=765322.00)

    if st.button("Predict Segment"):
        features = np.array([[recency, frequency, monetary]])
        features_scaled = scaler.transform(features)
        cluster = kmeans.predict(features_scaled)[0]

        # --- Interpret Cluster (Re-using logic from your original app.py) ---
        # This function directly maps the input RFM values to a segment label
        # based on fixed thresholds, similar to how it was done in your initial app.py and notebook.
        # It's important to note that this interpretation is separate from the KMeans cluster ID
        # but is designed to give a human-readable segment.
        def interpret_cluster(rec, freq, mon):
            # These thresholds are hardcoded and might need adjustment based on your data's actual quantiles
            # or based on the characteristics of the clusters KMeans found.
            if rec < 30 and freq > 50 and mon > 1000:
                return "High-Value"
            elif freq > 20 and mon > 500:
                return "Regular"
            elif rec > 90:
                return "At-Risk"
            else:
                return "Occasional"

        segment_label = interpret_cluster(recency, frequency, monetary)
        st.write(f"Predicted Cluster: **{cluster}**") # Shows the numerical cluster ID, like '2' in screenshot
        st.success(f"This customer belongs to: **{segment_label} Shopper**") # Shows the interpreted segment label

# --- Product Recommendation Page ---
elif page == "Recommendation":
    st.title("üì¶ Product Recommendation")
    st.markdown("Select a product to get recommendations for similar products.")

    # Get unique StockCodes from item_similarity_df for dropdown
    all_product_codes = item_similarity_df.index.tolist()

    # Use a selectbox for "Product Name" (which are StockCodes here)
    selected_product_code = st.selectbox("Select a Product:", [""] + all_product_codes)

    if st.button("Get Recommendations"):
        if selected_product_code and selected_product_code in item_similarity_df.index:
            # Get top 5 similar items, excluding the product itself
            recommendations = item_similarity_df[selected_product_code].sort_values(ascending=False)[1:6]

            st.write(f"Top 5 similar products for **{selected_product_code}**:")
            for i, (item_code, score) in enumerate(recommendations.items(), 1):
                # If you had product_code_to_name mapping, you could display product_code_to_name.get(item_code, item_code)
                st.write(f"{i}. {item_code} (Similarity: {score:.2f})")
        elif not selected_product_code:
            st.warning("Please select a product.")
        else:
            # This case should ideally not be hit if selection is from dropdown
            st.error("Selected product not found in the similarity matrix.")

"""**Conclusion : The Shopper Spectrum project successfully leverages RFM analysis and collaborative filtering to enhance e-commerce decision-making. By segmenting customers into distinct groups (High-Value, Regular, Occasional, At-Risk), businesses can tailor marketing strategies to improve retention and engagement. The product recommendation system further personalizes the shopping experience by suggesting relevant items, driving sales and customer satisfaction.

Deployed via Streamlit, this solution provides an intuitive interface for real-time insights. The integration of clustering (KMeans) and item-based collaborative filtering demonstrates the power of data-driven approaches in retail analytics. Future enhancements could include real-time data updates and hybrid recommendation models for even greater accuracy.

This project highlights the importance of customer segmentation and personalized recommendations in boosting e-commerce growth.**
"""